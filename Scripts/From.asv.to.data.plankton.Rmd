---
title: "From ASV to data.plankton"
output: html_notebook
---

This script will take the ASV table from the pipeline, and combine it with three metadata sources:
  * Taxonomical annotation
  * Biomineralization & lifestyle; these two have already been combined in the Rmarkdown "taxonomy.biom.food.env.Rmd"
  * Environmental data

And will create the final dataset of plankton species, with their Normalized reads and the environmental data associated with them



```{r}
library (tidyverse)
library (here)
source(here("Scripts", "eDNAindex.R"))
ASV.table  <- read_csv(here("Input", "ASV_table_all_together.csv"))
Annotation <- read_csv(here("Input", "hash.annotated.csv"))
env.data   <- read_csv(here("Input", "env.data.updated.csv"))
```


```{r}
ASV.table %>% 
  filter(!Hash %in%  (Annotation %>% 
           filter (str_detect(species, "Homo")) %>% 
           pull(Hash))) -> ASV.table


left_join(ASV.table, Annotation) %>% 
  unite(family, genus, species, col = "taxa", sep = "|") %>% 
  filter(taxa != "NA|NA|NA") %>% 
  select(taxa, sample, nReads, benthos) %>% 
  group_by(taxa, benthos, sample) %>% 
  summarise(nReads = sum(nReads)) -> ASV.by.taxa

ASV.by.taxa %>% 
  separate(sample, into = c("Site", "biol"), sep = "_", remove = F) %>% 
  separate(biol, into = c("biol", "tech.rep"), sep = "\\.") %>% 
  separate(biol, into = c("date", "biol.rep"), sep = -1) %>% 
  unite (Site, date, col = "event") -> ASV.by.taxa

ASV.by.taxa %>% 
  
  filter(!str_detect(event,"201710|201703" ) , benthos != "BEN") %>% 

  eDNAindex(Sample_column = event,
            OTU_column = taxa,
            Counts_column = nReads,
            Biological.replicate = biol.rep) -> ASV.plankton.event

ASV.plankton.event %>% 
  separate(event, into = c("Site", "Date")) %>% 
  mutate(Date = ymd(Date, truncated = T)) ->  ASV.plankton.event

env.data %>%  
   select( -contains("DO")) %>% 
   drop_na() %>% 
   right_join (ASV.plankton.event) %>% 
   unite (Site, Date, col = "event", sep = "_") %>% 
  write_csv(here("Input", "Combined_Biol_Env_Plankton.csv"))
```

